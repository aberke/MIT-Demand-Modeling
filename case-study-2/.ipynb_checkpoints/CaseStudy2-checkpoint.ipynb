{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demand Modeling - 1.202\n",
    "Problem Set 2: Linear Time Series Regression\n",
    "Alexandra Berke\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(\"Tran.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ln Vehicles/drivert</th>\n",
       "      <th>ln GDP/capitat</th>\n",
       "      <th>ln Pfuel/gal,t</th>\n",
       "      <th>ln pvehicle</th>\n",
       "      <th>ln LFPt</th>\n",
       "      <th>ln psuburbst</th>\n",
       "      <th>ln Vehicles/drivert-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "      <td>6.615782</td>\n",
       "      <td>2.231855</td>\n",
       "      <td>0.412110</td>\n",
       "      <td>9.614004</td>\n",
       "      <td>4.080922</td>\n",
       "      <td>-1.461018</td>\n",
       "      <td>6.615782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951</td>\n",
       "      <td>6.638924</td>\n",
       "      <td>2.314206</td>\n",
       "      <td>0.350657</td>\n",
       "      <td>9.603260</td>\n",
       "      <td>4.080922</td>\n",
       "      <td>-1.431292</td>\n",
       "      <td>6.615782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952</td>\n",
       "      <td>6.624696</td>\n",
       "      <td>2.333203</td>\n",
       "      <td>0.350657</td>\n",
       "      <td>9.595399</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>-1.406497</td>\n",
       "      <td>6.638924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953</td>\n",
       "      <td>6.639866</td>\n",
       "      <td>2.353691</td>\n",
       "      <td>0.378436</td>\n",
       "      <td>9.588914</td>\n",
       "      <td>4.075841</td>\n",
       "      <td>-1.378326</td>\n",
       "      <td>6.624696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954</td>\n",
       "      <td>6.649138</td>\n",
       "      <td>2.329221</td>\n",
       "      <td>0.385262</td>\n",
       "      <td>9.580869</td>\n",
       "      <td>4.074142</td>\n",
       "      <td>-1.350927</td>\n",
       "      <td>6.639866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  ln Vehicles/drivert  ln GDP/capitat  ln Pfuel/gal,t  ln pvehicle  \\\n",
       "0  1950             6.615782        2.231855        0.412110     9.614004   \n",
       "1  1951             6.638924        2.314206        0.350657     9.603260   \n",
       "2  1952             6.624696        2.333203        0.350657     9.595399   \n",
       "3  1953             6.639866        2.353691        0.378436     9.588914   \n",
       "4  1954             6.649138        2.329221        0.385262     9.580869   \n",
       "\n",
       "    ln LFPt  ln psuburbst  ln Vehicles/drivert-1  \n",
       "0  4.080922     -1.461018               6.615782  \n",
       "1  4.080922     -1.431292               6.615782  \n",
       "2  4.077537     -1.406497               6.638924  \n",
       "3  4.075841     -1.378326               6.624696  \n",
       "4  4.074142     -1.350927               6.639866  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The following are the equations that will be used:\n",
    "\n",
    "ln VMT/Vehiclet = b0 + b1 ln GDP/capitat + b2 ln Pfuel/gal,t + b3 ln MPGt + b4 ln Vehicles/drivert + b5 ln psuburbst + b6 ln VMT/Vehiclet-1 + et (7)\n",
    "Where b0 = ln k0, and et = ln ht is a stochastic disturbance representing variables omitted from the model and other noise in the data.\n",
    "\n",
    "The vehicles-per-driver term reflects the size and rate of utilization of the vehicle stock. Since the vehicle stock may change in the long run, Pickrell modeled it as\n",
    "ln Vehicles/drivert = g0 + g1 ln GDP/capitat + g2 ln Pfuel/gal,t + g3 ln Pveh,t + g4 ln LFPt + g5 ln psuburbst + g6 ln Vehicles/drivert-1 + xt\n",
    "\n",
    "\n",
    "I create 2 new dataframes, one for each of the equations.\n",
    "Each dataframe contains the variables for their equations, transformed as needed.\n",
    "i.e. each row of a dataframe contains the explanatory variable, as well as each independent variable including\n",
    "lagged variables, which are pulled from the previous row's data.\n",
    "\n",
    "For variables that were already present in the data, I simply take their natural log.\n",
    "Some variables were first constructed them from other variables as proportions.\n",
    "\n",
    "\"\"\"\n",
    "# Variables needed as columns of dataframes:\n",
    "YEAR = \"year\"\n",
    "LOG_VMT_PER_VEHICLE = \"ln VMT/Vehiclet\"\n",
    "LOG_GDP_PER_CAPITA = \"ln GDP/capitat\"  # I compute GDP/capita as GDP/pop\n",
    "LOG_PFUEL_PER_GALLON = \"ln Pfuel/gal,t\" # This is pgas in the dataset\n",
    "LOG_MPG = \"ln MPGt\"  # average fuel efficiency of automobiles and two-axle, four-tire trucks (miles per gallon)\n",
    "LOG_VEHICLES_PER_DRIVER = \"ln Vehicles/drivert\"\n",
    "LOG_PSUBURBS = \"ln psuburbst\" # proportion of U.S. population living in urbanized areas who live in suburban portions of urban areas (using Census Bureau definitions)\n",
    "LOG_LAGGED_VMT_PER_VEHICLE = \"ln VMT/Vehiclet-1\"\n",
    "# Additional variables for vehicle stock equation\n",
    "LOG_PRICEVEHICLE = \"ln pvehicle\"  # average price of a new automobile in 1987 U.S. dollars\n",
    "LOG_LFP = \"ln LFPt\"  # percent of working-age U.S. population employed or actively seeking work\n",
    "LOG_LAGGED_VEHICLES_PER_DRIVER = \"ln Vehicles/drivert-1\"\n",
    "\n",
    "# Construct the dataframe for equation (7)\n",
    "# ln VMT/Vehiclet = b0 + b1 ln GDP/capitat + b2 ln Pfuel/gal,t + b3 ln MPGt + b4 ln Vehicles/drivert + b5 ln psuburbst + b6 ln VMT/Vehiclet-1 + et (7)\n",
    "vmt_per_vehicle_df = pd.DataFrame(data={\n",
    "    YEAR: df[YEAR],\n",
    "    LOG_VMT_PER_VEHICLE: np.log(df[\"vmt\"]/df[\"vehicles\"]),\n",
    "    LOG_GDP_PER_CAPITA: np.log(df[\"gdp\"]/df[\"pop\"]),\n",
    "    LOG_PFUEL_PER_GALLON: np.log(df[\"pgas\"]),\n",
    "    LOG_MPG: np.log(df[\"mpg\"]),\n",
    "    LOG_VEHICLES_PER_DRIVER: np.log(df[\"vehicles\"]/df[\"drivers\"])\n",
    "})\n",
    "vmt_per_vehicle_df.set_index(YEAR)\n",
    "# psuburbs values are missing for the last 4 years of data.\n",
    "# I insert the last available psuburbs value for these missing datapoints.  This insertion\n",
    "# seems valid because the values were gradually growing, thought somewhat stagnant in\n",
    "# the final years of data.  Inserting zeros for the missing values would contribute error to the\n",
    "# model.\n",
    "psuburbs = pd.to_numeric(df[\"psuburbs\"], errors=\"coerce\")\n",
    "for i in range(len(psuburbs)):\n",
    "    ps = psuburbs[i-1] if pd.isna(psuburbs[i]) else psuburbs[i]\n",
    "    psuburbs[i] = ps\n",
    "    \n",
    "vmt_per_vehicle_df[LOG_PSUBURBS] = np.log(psuburbs)\n",
    "\n",
    "# Add in the lagged variable:\n",
    "# To add in the lagged variables, I added to each row of data the value for the previous row.\n",
    "# For example, the value of ln Vehicles/drivert-1 for t=1954 is the value of ln Vehicles/driver for t=1953.\n",
    "# To handle the first year of data (1950) for which the previous year’s data was not available,\n",
    "# I insert the first year’s data to serve as a proxy.\n",
    "# i.e. Vehicles/drivert-1 = Vehicles/drivert when t=1950.\n",
    "log_vmt_per_vehicles = vmt_per_vehicle_df[LOG_VMT_PER_VEHICLE]\n",
    "log_lagged_vmt_per_vehicles = [log_vmt_per_vehicles[0] if i == 0 else log_vmt_per_vehicles[i-1] for i in range(len(log_vmt_per_vehicles))]\n",
    "vmt_per_vehicle_df[LOG_LAGGED_VMT_PER_VEHICLE] = log_lagged_vmt_per_vehicles\n",
    "\n",
    "\n",
    "# Construct the dataframe for equation (8)\n",
    "# ln Vehicles/drivert = g0 + g1 ln GDP/capitat + g2 ln Pfuel/gal,t + g3 ln Pveh,t + g4 ln LFPt + g5 ln psuburbst + g6 ln Vehicles/drivert-1 + xt (8)\n",
    "\n",
    "# pvehicle values are missing for the last 4 years of data.\n",
    "# lfp values are missing for the last 2 years of data.\n",
    "# I insert the last available value for these missing datapoints.\n",
    "pvehicle = pd.to_numeric(df[\"pvehicle\"], errors=\"coerce\")\n",
    "for i in range(len(pvehicle)):\n",
    "    pvehicle[i] = pvehicle[i-1] if pd.isna(pvehicle[i]) else pvehicle[i]\n",
    "\n",
    "lfp = pd.to_numeric(df[\"lfp\"], errors=\"coerce\")\n",
    "for i in range(len(lfp)):\n",
    "    lfp[i] = lfp[i-1] if pd.isna(lfp[i]) else lfp[i]\n",
    "\n",
    "vehicles_per_driver_df = pd.DataFrame(data={\n",
    "    YEAR: df[YEAR],\n",
    "    LOG_VEHICLES_PER_DRIVER: np.log(df[\"vehicles\"]/df[\"drivers\"]),\n",
    "    LOG_GDP_PER_CAPITA: np.log(df[\"gdp\"]/df[\"pop\"]),\n",
    "    LOG_PFUEL_PER_GALLON: np.log(df[\"pgas\"]),\n",
    "    LOG_PRICEVEHICLE: np.log(pvehicle),\n",
    "    LOG_LFP: np.log(lfp),\n",
    "    LOG_PSUBURBS: np.log(psuburbs)\n",
    "})\n",
    "vehicles_per_driver_df.set_index(YEAR)\n",
    "\n",
    "# Add in the lagged variable ln Vehicles/drivert-1\n",
    "log_vehicles_per_driver = vehicles_per_driver_df[LOG_VEHICLES_PER_DRIVER]\n",
    "log_lagged_vehicles_per_driver = [log_vehicles_per_driver[0] if i == 0 else log_vehicles_per_driver[i-1] for i in range(len(log_vehicles_per_driver))]\n",
    "vehicles_per_driver_df[LOG_LAGGED_VEHICLES_PER_DRIVER] = log_lagged_vehicles_per_driver\n",
    "\n",
    "vehicles_per_driver_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        ln VMT/Vehiclet   R-squared:                       0.954\n",
      "Model:                            OLS   Adj. R-squared:                  0.947\n",
      "Method:                 Least Squares   F-statistic:                     132.7\n",
      "Date:                Mon, 18 Mar 2019   Prob (F-statistic):           6.26e-24\n",
      "Time:                        11:28:51   Log-Likelihood:                 136.57\n",
      "No. Observations:                  45   AIC:                            -259.1\n",
      "Df Residuals:                      38   BIC:                            -246.5\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   2.6565      1.013      2.624      0.012       0.607       4.706\n",
      "ln GDP/capitat          0.1698      0.088      1.932      0.061      -0.008       0.348\n",
      "ln Pfuel/gal,t         -0.0868      0.020     -4.422      0.000      -0.127      -0.047\n",
      "ln MPGt                 0.0611      0.028      2.154      0.038       0.004       0.119\n",
      "ln Vehicles/drivert    -0.3426      0.156     -2.190      0.035      -0.659      -0.026\n",
      "ln psuburbst            0.0587      0.058      1.010      0.319      -0.059       0.176\n",
      "ln VMT/Vehiclet-1       0.6332      0.076      8.292      0.000       0.479       0.788\n",
      "==============================================================================\n",
      "Omnibus:                        6.805   Durbin-Watson:                   1.476\n",
      "Prob(Omnibus):                  0.033   Jarque-Bera (JB):                5.617\n",
      "Skew:                          -0.736   Prob(JB):                       0.0603\n",
      "Kurtosis:                       3.911   Cond. No.                     4.51e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.51e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"2. Prompt: Replicate each of Pickrell’s models (equations 7 and 8) using OLS.\n",
    "\n",
    "Interpret your estimates of the parameters.\n",
    "\n",
    "Are they statistically significant?\n",
    "\n",
    "What are the short- and long-run estimates of the elasticity of VMT with\n",
    "respect to gasoline price and income (GDP per capita)? \n",
    "\"\"\"\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Modeling VMT/Vehicle model:\n",
    "vmt_per_vehicle_model_X = sm.add_constant(vmt_per_vehicle_df[[\n",
    "                                  LOG_GDP_PER_CAPITA,\n",
    "                                  LOG_PFUEL_PER_GALLON,\n",
    "                                  LOG_MPG,\n",
    "                                  LOG_VEHICLES_PER_DRIVER,\n",
    "                                  LOG_PSUBURBS,\n",
    "                                  LOG_LAGGED_VMT_PER_VEHICLE\n",
    "                              ]])\n",
    "vmt_per_vehicle_model_Y = vmt_per_vehicle_df[LOG_VMT_PER_VEHICLE]\n",
    "vmt_per_vehicle_results = sm.OLS(vmt_per_vehicle_model_Y, vmt_per_vehicle_model_X).fit()\n",
    "\n",
    "print(vmt_per_vehicle_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2366412213740458\n",
      "0.4629225736095965\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Calculating long-run elasticities for VMT/vehicle w.r.t price of gas and income\n",
    "The long-run estimates assume that equilibrium for VMT per vehicle has been reached,\n",
    "i.e. that VMT/vehicle for year t is the same as VMT/vehicle for year t-1.\n",
    "\"\"\"\n",
    "\n",
    "#  For price of fuel/gallon\n",
    "#  (coefficient for price of fuel/gallon)/(1 - coefficient for VMT/vehicle)\n",
    "print((-0.0868)/(1 - 0.6332))\n",
    "\n",
    "# For income (GDP/capita) the long-run elasticity  estimate is \n",
    "# = (coefficient of GDP/capita) / (1 - coefficient for VMT/vehicle)\n",
    "print((0.1698)/(1 - 0.6332))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     ln Vehicles/drivert   R-squared:                       0.995\n",
      "Model:                             OLS   Adj. R-squared:                  0.995\n",
      "Method:                  Least Squares   F-statistic:                     1390.\n",
      "Date:                 Mon, 18 Mar 2019   Prob (F-statistic):           6.21e-43\n",
      "Time:                         11:28:54   Log-Likelihood:                 147.80\n",
      "No. Observations:                   45   AIC:                            -281.6\n",
      "Df Residuals:                       38   BIC:                            -269.0\n",
      "Df Model:                            6                                         \n",
      "Covariance Type:             nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     3.2659      0.633      5.159      0.000       1.984       4.548\n",
      "ln GDP/capitat            0.1856      0.053      3.491      0.001       0.078       0.293\n",
      "ln Pfuel/gal,t            0.0069      0.014      0.477      0.636      -0.022       0.036\n",
      "ln pvehicle              -0.0492      0.021     -2.307      0.027      -0.092      -0.006\n",
      "ln LFPt                   0.0176      0.172      0.102      0.919      -0.331       0.366\n",
      "ln psuburbst              0.0871      0.047      1.864      0.070      -0.008       0.182\n",
      "ln Vehicles/drivert-1     0.5222      0.109      4.806      0.000       0.302       0.742\n",
      "==============================================================================\n",
      "Omnibus:                        0.808   Durbin-Watson:                   1.826\n",
      "Prob(Omnibus):                  0.668   Jarque-Bera (JB):                0.211\n",
      "Skew:                          -0.076   Prob(JB):                        0.900\n",
      "Kurtosis:                       3.300   Cond. No.                     5.56e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.56e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Modeling VMT/Vehicle model:\n",
    "vehicles_per_driver_model_X = sm.add_constant(vehicles_per_driver_df[[\n",
    "                                  LOG_GDP_PER_CAPITA,\n",
    "                                  LOG_PFUEL_PER_GALLON,\n",
    "                                  LOG_PRICEVEHICLE,\n",
    "                                  LOG_LFP,\n",
    "                                  LOG_PSUBURBS,\n",
    "                                  LOG_LAGGED_VEHICLES_PER_DRIVER\n",
    "                              ]])\n",
    "vehicles_per_driver_model_Y = vehicles_per_driver_df[LOG_VEHICLES_PER_DRIVER]\n",
    "vehicles_per_driver_results = sm.OLS(vehicles_per_driver_model_Y, vehicles_per_driver_model_X).fit()\n",
    "\n",
    "print(vehicles_per_driver_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h stat for VMT/vehicle: 2.0429992830872603\n",
      "checking s*s > 1/T: False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Part c) Test for autocorrelation:\n",
    "I use the Durbin’s Lagrange Multiplier Test in order to test the null hypothesis of no serial correlation.\n",
    "\n",
    "h = (1-(d/2))sqrt(T/(1-Ts*s)))\n",
    "\n",
    "Where\n",
    "d = The Durbin-Watson statistic (which was included in the model output for the OLS regressions run)\n",
    "T = Number of time periods (45 in total for 1950 - 1994).\n",
    "s = standard error of the coefficient on the lagged endogenous variable.\n",
    "\"\"\"\n",
    "\n",
    "def durbin_lagrange_multiplier_test(d, T, s):\n",
    "    \"\"\"Returns h = (1-(d/2))sqrt(T/(1-Ts*s)))\n",
    "    Where\n",
    "    d = The Durbin-Watson statistic (which was included in the model output for the OLS regressions run)\n",
    "    T = Number of time periods (45 in total for 1950 - 1994).\n",
    "    s = standard error of the coefficient on the lagged endogenous variable.\n",
    "    \"\"\"\n",
    "    return (1-(d/2))*np.sqrt(T/(1-(T*s*s)))\n",
    "\n",
    "# Test for equation (7) VMT/vehicle\n",
    "d = 1.476 # The Durbin-Watson statistic\n",
    "T = 45\n",
    "s = 0.076\n",
    "h = durbin_lagrange_multiplier_test(d, T, s)\n",
    "print('h stat for VMT/vehicle:', h)\n",
    "\n",
    "print (\"checking s*s > 1/T:\", s*s > 1/T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h stat for VMT/vehicle: 0.8555262061724588\n",
      "checking s*s > 1/T: False\n"
     ]
    }
   ],
   "source": [
    "# Test for equation (8) Vehicles/Driver\n",
    "d = 1.826 # The Durbin-Watson statistic\n",
    "T = 45\n",
    "s = 0.109\n",
    "h = durbin_lagrange_multiplier_test(d, T, s)\n",
    "print('h stat for VMT/vehicle:', h)\n",
    "\n",
    "print (\"checking s*s > 1/T:\", s*s > 1/T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        ln VMT/Vehiclet   R-squared:                       0.872\n",
      "Model:                            OLS   Adj. R-squared:                  0.856\n",
      "Method:                 Least Squares   F-statistic:                     53.14\n",
      "Date:                Mon, 18 Mar 2019   Prob (F-statistic):           2.28e-16\n",
      "Time:                        11:29:00   Log-Likelihood:                 113.32\n",
      "No. Observations:                  45   AIC:                            -214.6\n",
      "Df Residuals:                      39   BIC:                            -203.8\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   5.3845      1.585      3.398      0.002       2.180       8.589\n",
      "ln GDP/capitat          0.4348      0.135      3.210      0.003       0.161       0.709\n",
      "ln Pfuel/gal,t         -0.1731      0.028     -6.289      0.000      -0.229      -0.117\n",
      "ln MPGt                 0.0743      0.047      1.585      0.121      -0.021       0.169\n",
      "ln Vehicles/drivert    -0.6392      0.252     -2.536      0.015      -1.149      -0.129\n",
      "ln psuburbst            0.0300      0.096      0.313      0.756      -0.164       0.224\n",
      "==============================================================================\n",
      "Omnibus:                        5.436   Durbin-Watson:                   0.478\n",
      "Prob(Omnibus):                  0.066   Jarque-Bera (JB):                4.193\n",
      "Skew:                          -0.629   Prob(JB):                        0.123\n",
      "Kurtosis:                       3.809   Cond. No.                     4.10e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.1e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Part d)\n",
    "For each model where you conclude autocorrelation exists (based on (c)),\n",
    "reestimate the Pickrell’s model without the lagged endogenous variable.\n",
    "Examine specifications of your own.\n",
    "Can you come up with a model that has more explanatory power than Pickrell’s?\n",
    "Use the Durbin-Watson statistic to test for first order autocorrelation in your best model.\n",
    "What are the properties (e.g., consistency, efficiency) of your OLS estimates when autocorrelation\n",
    "is present and when autocorrelation is not present?\n",
    "\n",
    "\n",
    "I estimate the 2 additional models without lagged endogenous variables:\n",
    "\n",
    "Pickrell’s model without the lagged variable\n",
    "(1)  ln VMT/Vehiclet = b0 + b1 ln GDP/capitat + b2 ln Pfuel/gal,t + b3 ln MPGt + b4 ln Vehicles/drivert + b5 ln psuburbst + et\n",
    "\n",
    "And a model of my own specification, which is similar to Pickrell’s original model, but different in the following\n",
    "ways:\n",
    "- The lagged endogenous variable VMT/Vehicles is removed\n",
    "- The psuburbs variable is  removed because it was not statistically significant in the original model.\n",
    "- I compute and add an additional variable: roads/vehicles.\n",
    "My intuition for adding the roads/vehicles explanatory variable is inspired by the common belief of urban\n",
    "planners “if you build it, they will come”.\n",
    "\n",
    "(2)  ln VMT/Vehiclet = b0 + b1 ln GDP/capitat + b2 ln Pfuel/gal,t + b3 ln MPGt + b4 ln Vehicles/drivert + b5 ln roads/vehiclest  + et\n",
    "\"\"\"\n",
    "\n",
    "# OLS Estimate for:\n",
    "# (1)  ln VMT/Vehiclet = b0 + b1 ln GDP/capitat + b2 ln Pfuel/gal,t + b3 ln MPGt + b4 ln Vehicles/drivert + b5 ln psuburbst + et\n",
    "\n",
    "vmt_per_vehicle_model_1_X = sm.add_constant(vmt_per_vehicle_df[[\n",
    "                                  LOG_GDP_PER_CAPITA,\n",
    "                                  LOG_PFUEL_PER_GALLON,\n",
    "                                  LOG_MPG,\n",
    "                                  LOG_VEHICLES_PER_DRIVER,\n",
    "                                  LOG_PSUBURBS\n",
    "                              ]])\n",
    "vmt_per_vehicle_model_1_Y = vmt_per_vehicle_df[LOG_VMT_PER_VEHICLE]\n",
    "vmt_per_vehicle_results_1 = sm.OLS(vmt_per_vehicle_model_1_Y, vmt_per_vehicle_model_1_X).fit()\n",
    "\n",
    "print(vmt_per_vehicle_results_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        ln VMT/Vehiclet   R-squared:                       0.877\n",
      "Model:                            OLS   Adj. R-squared:                  0.861\n",
      "Method:                 Least Squares   F-statistic:                     55.54\n",
      "Date:                Sun, 17 Mar 2019   Prob (F-statistic):           1.08e-16\n",
      "Time:                        18:08:01   Log-Likelihood:                 114.19\n",
      "No. Observations:                  45   AIC:                            -216.4\n",
      "Df Residuals:                      39   BIC:                            -205.5\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   3.7919      1.502      2.525      0.016       0.754       6.830\n",
      "ln GDP/capitat          0.4341      0.133      3.276      0.002       0.166       0.702\n",
      "ln Pfuel/gal,t         -0.1601      0.028     -5.688      0.000      -0.217      -0.103\n",
      "ln MPGt                 0.1213      0.059      2.040      0.048       0.001       0.242\n",
      "ln Vehicles/drivert    -0.4826      0.223     -2.168      0.036      -0.933      -0.032\n",
      "ln roads/vehicles       0.1343      0.105      1.281      0.208      -0.078       0.346\n",
      "==============================================================================\n",
      "Omnibus:                        3.729   Durbin-Watson:                   0.469\n",
      "Prob(Omnibus):                  0.155   Jarque-Bera (JB):                2.695\n",
      "Skew:                          -0.570   Prob(JB):                        0.260\n",
      "Kurtosis:                       3.373   Cond. No.                     4.15e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.15e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# OLS Estimate for:\n",
    "# (2)  ln VMT/Vehiclet = b0 + b1 ln GDP/capitat + b2 ln Pfuel/gal,t + b3 ln MPGt + b4 ln Vehicles/drivert + b5 ln roads/vehiclest  + et\n",
    "# first compute ln roads/vehicles variable\n",
    "LOG_ROADS_PER_VEHICLES = \"ln roads/vehicles\"\n",
    "# roads values are missing for the last 2 years of data -- insert last available values into missing rows\n",
    "roads = pd.to_numeric(df[\"roads\"], errors=\"coerce\")\n",
    "for i in range(len(roads)):\n",
    "    roads[i] = roads[i-1] if pd.isna(roads[i]) else roads[i]\n",
    "log_roads_per_vehicles = np.log(roads/df[\"vehicles\"])\n",
    "# Add this new variable to the df\n",
    "vmt_per_vehicle_df[LOG_ROADS_PER_VEHICLES] = log_roads_per_vehicles\n",
    "\n",
    "vmt_per_vehicle_model_2_X = sm.add_constant(vmt_per_vehicle_df[[\n",
    "                                  LOG_GDP_PER_CAPITA,\n",
    "                                  LOG_PFUEL_PER_GALLON,\n",
    "                                  LOG_MPG,\n",
    "                                  LOG_VEHICLES_PER_DRIVER,\n",
    "                                  LOG_ROADS_PER_VEHICLES\n",
    "                              ]])\n",
    "vmt_per_vehicle_model_2_Y = vmt_per_vehicle_df[LOG_VMT_PER_VEHICLE]\n",
    "vmt_per_vehicle_results_2 = sm.OLS(vmt_per_vehicle_model_2_Y, vmt_per_vehicle_model_2_X).fit()\n",
    "\n",
    "print(vmt_per_vehicle_results_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cochrane-orcutt iteration 1\n",
      "p_estimate 0.7658540899060109\n",
      "new params: [ 4.72160436  0.34217797 -0.12759275  0.17702364 -0.54939502  0.02331098] \n",
      "\n",
      "cochrane-orcutt iteration 2\n",
      "p_estimate 0.8469407173766601\n",
      "new params: [ 4.6353444   0.33293047 -0.12247375  0.2063709  -0.54855908 -0.00661573] \n",
      "\n",
      "abs(p_estimate_old - p_estimate) 0.08108662747064921\n",
      "cochrane-orcutt iteration 3\n",
      "p_estimate 0.8654673140474386\n",
      "new params: [ 4.59928646  0.33103601 -0.12157045  0.21401217 -0.5476801  -0.02404608] \n",
      "\n",
      "abs(p_estimate_old - p_estimate) 0.018526596670778495\n",
      "cochrane-orcutt iteration 4\n",
      "p_estimate 0.8746969284566184\n",
      "new params: [ 4.57681742  0.33002897 -0.12114081  0.21788787 -0.54696549 -0.0360723 ] \n",
      "\n",
      "abs(p_estimate_old - p_estimate) 0.009229614409179798\n",
      "New p_estimate differs from last p_estimate by < 0.01.  Ending procedure\n",
      "completed cochrane-orcutt procedure after 4 iterations\n",
      "final parameters: const: 4.5768174216002535, ln GDP/capitat: 0.3300289667214744, ln Pfuel/gal,t: -0.12114081394586919, ln MPGt: 0.21788787146600525, ln Vehicles/drivert: -0.5469654919701199, ln psuburbst: -0.036072298868261354\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Part e) Use the Iterative Cochrane-Orcutt procedure described in Appendix C\n",
    "to correct for first order autocorrelation and to estimate the correlation between\n",
    "successive stochastic error terms.\n",
    "With first order autocorrelation permitted, are your elasticity estimates substantially changed?\n",
    "Which results are more plausible and credible, those in part (b) or here? Why?\n",
    "\"\"\"\n",
    "\n",
    "CO_MAX_ITERATIONS = 15\n",
    "co_iterations = 0\n",
    "p_estimate_old = None\n",
    "\n",
    "# Step 1\n",
    "#Ordinary least squares is used to estimate the original model, Eq. (9).\n",
    "co_procedure_model_X = sm.add_constant(vmt_per_vehicle_df[[\n",
    "                                  LOG_GDP_PER_CAPITA,\n",
    "                                  LOG_PFUEL_PER_GALLON,\n",
    "                                  LOG_MPG,\n",
    "                                  LOG_VEHICLES_PER_DRIVER,\n",
    "                                  LOG_PSUBURBS\n",
    "                              ]])\n",
    "X_columns = co_procedure_model_X.columns\n",
    "co_procedure_model_Y = vmt_per_vehicle_df[LOG_VMT_PER_VEHICLE]\n",
    "\n",
    "co_step1_results = sm.OLS(co_procedure_model_Y, co_procedure_model_X).fit()\n",
    "params = co_step1_results.params\n",
    "\n",
    "while(co_iterations <= CO_MAX_ITERATIONS):\n",
    "    co_iterations += 1\n",
    "    print('cochrane-orcutt iteration', co_iterations)\n",
    "    \n",
    "    # Step 2. The estimated parameters are used to construct residuals\n",
    "    fittedvalues = np.dot(co_procedure_model_X, [param for param in params])\n",
    "    co_procedure_residuals = co_procedure_model_Y - fittedvalues\n",
    "\n",
    "\n",
    "    # These residuals are then used to perform the regression to get an estimate for p\n",
    "    # et = p*et-1 + nt\n",
    "    e_t = [e for e in co_procedure_residuals[1:]]\n",
    "    e_t_1 = co_procedure_residuals[:-1]\n",
    "\n",
    "    co_step2_results = sm.OLS(e_t, e_t_1).fit()\n",
    "    p_estimate = co_step2_results.params[0]\n",
    "    print('p_estimate', p_estimate)\n",
    "\n",
    "    # Step 3. The estimated value of p is used to perform the generalized differencing transformation process,\n",
    "    # and a new regression is run. The transformed equation is\n",
    "    # Y_star_t =b0*(1-p) + b*X_star_t + vt\n",
    "    # where\n",
    "    # Y_star_t = Y_t - pY_t-1\n",
    "    # X_star_t = X_t - p*X_t-1\n",
    "    # v_t = e_t - p*e_t-1\n",
    "    T = len(co_procedure_model_Y)\n",
    "    Y_star = [co_procedure_model_Y[t] - p_estimate*co_procedure_model_Y[t-1] for t in range(1, T)]\n",
    "    X_star = [co_procedure_model_X.iloc[t] - p_estimate*co_procedure_model_X.iloc[t-1] for t in range(1, T)]\n",
    "    v = e_t - p_estimate*e_t_1\n",
    "\n",
    "    # Step 4. The estimated transformed equation yields new estimates for the parameter vector b. These revised parameter estimates are substituted into the original equation, and new regression residuals are obtained. That is, the new estimate of b is used upon returning to Step 2 to obtain a new estimate of r.\n",
    "    # The iterative process can be carried on for as many steps as the researcher desires. Standard procedure is to stop the iterations when the new estimates of r differ from the old ones by less than\n",
    "    # 0.01 or 0.005, or after 10 or 20 estimates of r have been obtained. The specific choice made depends upon the computational costs involved. The primary difficulty with the Cochrane-Orcutt procedure is that there is no guarantee that the final estimate of r will be the optimal estimate, in the sense of minimizing the sum of squared residuals. The difficulty arises because the iterative technique may lead to a local rather than a global minimum.\n",
    "    co_step1_results = sm.OLS(Y_star, X_star).fit()\n",
    "    params = co_step1_results.params\n",
    "    print('new params:', params, '\\n')\n",
    "\n",
    "    if (p_estimate_old is not None):\n",
    "        p_estimate_diff = abs(p_estimate_old - p_estimate)\n",
    "        print('abs(p_estimate_old - p_estimate)', abs(p_estimate_old - p_estimate))\n",
    "        if (p_estimate_diff < 0.01):\n",
    "            print('New p_estimate differs from last p_estimate by < 0.01.  Ending procedure')\n",
    "            break\n",
    "    p_estimate_old = p_estimate\n",
    "    \n",
    "print('completed cochrane-orcutt procedure after', co_iterations, 'iterations')\n",
    "print('final parameters:', \", \".join([X_columns[i] + ': ' + str(params[i]) for i in range(len(params))]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        ln VMT/Vehiclet   R-squared:                       0.871\n",
      "Model:                            OLS   Adj. R-squared:                  0.828\n",
      "Method:                 Least Squares   F-statistic:                     20.23\n",
      "Date:                Sun, 17 Mar 2019   Prob (F-statistic):           3.50e-06\n",
      "Time:                        22:56:29   Log-Likelihood:                 76.628\n",
      "No. Observations:                  21   AIC:                            -141.3\n",
      "Df Residuals:                      15   BIC:                            -135.0\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   5.6126      1.205      4.659      0.000       3.045       8.180\n",
      "ln GDP/capitat          0.2438      0.080      3.052      0.008       0.074       0.414\n",
      "ln Pfuel/gal,t          0.1203      0.072      1.679      0.114      -0.032       0.273\n",
      "ln MPGt                -0.8437      0.189     -4.472      0.000      -1.246      -0.442\n",
      "ln Vehicles/drivert    -0.2757      0.173     -1.597      0.131      -0.644       0.092\n",
      "ln psuburbst           -0.0492      0.051     -0.965      0.350      -0.158       0.060\n",
      "==============================================================================\n",
      "Omnibus:                        0.001   Durbin-Watson:                   1.990\n",
      "Prob(Omnibus):                  0.999   Jarque-Bera (JB):                0.164\n",
      "Skew:                           0.014   Prob(JB):                        0.921\n",
      "Kurtosis:                       2.567   Cond. No.                     5.84e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.84e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Part f) Now reestimate your best model specification from parts (b), (d) and (e) using only the data through 1970.\n",
    "It may be argued that the oil shocks of the 1970s and growing environmental consciousness may have led to a \n",
    "structural change in travel demand patterns.\n",
    "Do you agree with this assertion? Describe how you might test this assertion statistically.\n",
    "\n",
    "\n",
    "I compare the modified Pickrell model specification (1) for data thought only 1970 versus all of the data.\n",
    "\"\"\"\n",
    "vmt_per_vehicle_model_1_1970_X = sm.add_constant(vmt_per_vehicle_df[[\n",
    "  LOG_GDP_PER_CAPITA,\n",
    "  LOG_PFUEL_PER_GALLON,\n",
    "  LOG_MPG,\n",
    "  LOG_VEHICLES_PER_DRIVER,\n",
    "  LOG_PSUBURBS\n",
    "]].iloc[:21])\n",
    "vmt_per_vehicle_model_1_1970_Y = vmt_per_vehicle_df[LOG_VMT_PER_VEHICLE].iloc[:21]\n",
    "\n",
    "vmt_per_vehicle_results_1970_1_results = sm.OLS(vmt_per_vehicle_model_1_1970_Y, vmt_per_vehicle_model_1_1970_X).fit()\n",
    "print(vmt_per_vehicle_results_1970_1_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                  1.000000\n",
       "ln GDP/capitat         3.413999\n",
       "ln Pfuel/gal,t        -0.099747\n",
       "ln MPGt                3.124391\n",
       "ln Vehicles/drivert    6.993319\n",
       "ln psuburbst          -0.401334\n",
       "Name: 66, dtype: float64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Part g)\n",
    "Many urban planners and transportation professionals believe the hypothesis of \n",
    "“if you build it, they will come,” that is, that any increase in road capacity \n",
    "is immediately consumed by additional travel at congestion levels similar to \n",
    "before the road construction. Mark Kiefer and Shomik Mehndiratta (1998) present \n",
    "a counter-argument that while VMT and congestion have risen dramatically from the\n",
    "’50s to the ’90s, this growth in VMT should not be expected to continue in the future \n",
    "for two reasons: \n",
    "(1) the growth in labor-force participation should be tapering off now that labor-force \n",
    "participation among women is approaching that of men, and \n",
    "(2) the growth in household auto ownership appears to slowing to a rate of one vehicle per driver.\n",
    "Forecast the VMT/Vehicle for the year 2016 (that is, 1994, the last year of the data, \n",
    "plus a 22- year planning horizon) assuming LFP continues to grow at 0.3% per year and auto ownership \n",
    "(vehicles per drive) continues to grow at 0.9% per year — these are the average growth rates for 1950-1994. \n",
    "(Other average growth rates are GDP per capita, 1.8% per year; gasoline price, -0.8% per year; vehicle cost, \n",
    "0.2% per year; fuel efficiency, 0.7% per year; and proportion of suburbs, 1.7% per year. Do final forecast \n",
    "variables look reasonable?)\n",
    "Rerun your forecast of VMT/Vehicle for 2016 assuming that LFP stays constant at 66.3 percent, \n",
    "and auto ownership remains at 1.089 vehicles per driver. Is the difference in forecasts large enough that \n",
    "Kiefer and Mehndiratta’s hypothesis should be given more analysis?\n",
    "\n",
    "---\n",
    "\n",
    "To complete and compare the forecasts for year 2016, I again use the modified Pickrell model that excludes the use of a lagged variable:\n",
    "(1)  ln VMT/Vehiclet = b0 + b1 ln GDP/capitat + b2 ln Pfuel/gal,t + b3 ln MPGt + b4 ln Vehicles/drivert + b5 ln psuburbst + et\n",
    "\n",
    "Note that this model relies on the Vehicles/driver variable, but not LFP.  Therefore LFP will not be directly used in this model’s forecasts for 2016.\n",
    "\n",
    "I extended the available data into the year 2016 in two slightly different datasets:\n",
    "The first dataset uses the average growth rates of the provided data for all variables to project into the future.\n",
    "The second dataset is the same as the first, but it keeps the vehicles/drivers values constant at the last available value in the dataset (the value for 1994).\n",
    "\n",
    "I forecast VMT/Vehicle for year 2016 using the 2 different datasets.\n",
    "\"\"\"\n",
    "\n",
    "# To complete and compare the forecasts for year 2016, I again use the modified Pickrell model that\n",
    "# excludes the use of a lagged variable:\n",
    "# (1)  ln VMT/Vehiclet = b0 + b1 ln GDP/capitat + b2 ln Pfuel/gal,t + b3 ln MPGt + b4 ln Vehicles/drivert + b5 ln psuburbst + et\n",
    "\n",
    "# I extend the available data to 2016 by using the average growth rates of the provided data.\n",
    "# I create 2 new dataframes that extend the current vmt_per_vehicle_df dataframe to Year 2016:\n",
    "# 1. One dataframe vmt_per_vehicle_2016_1_df uses the current growth rates for all variables\n",
    "\n",
    "# 2. The second dataframe vmt_per_vehicle_2016_2_df is the same as vmt_per_vehicle_2016_1_df but keeps\n",
    "# vehicles/driver constant at the value for 1994.\n",
    "\n",
    "# Need to extend values, but first without the log.  Then take log of entire series.\n",
    "last_available_year_index = len(df) - 1\n",
    "year_extension_range = range(1, 2016 - 1994 + 1)\n",
    "\n",
    "def get_future_value(last_value, growth_rate, t):\n",
    "    return last_value*((1 + growth_rate)**t)\n",
    "\n",
    "years = pd.Series(range(1950, 2016 + 1))\n",
    "\n",
    "# Make new gdp per capita series -- annual growth rate: 1.8%\n",
    "gdp_per_capita = [v for v in df[\"gdp\"]/df[\"pop\"]]\n",
    "for t in year_extension_range:\n",
    "    gdp_per_capita.append(get_future_value(gdp_per_capita[last_available_year_index], 0.018, t))\n",
    "    \n",
    "gdp_per_capita = pd.Series(gdp_per_capita)\n",
    "\n",
    "# Make new Pfuel/gallon series -- annual growth rate: -0.8%\n",
    "pfuel_per_gallon = [v for v in df[\"pgas\"]]\n",
    "for t in year_extension_range:\n",
    "    pfuel_per_gallon.append(get_future_value(pfuel_per_gallon[last_available_year_index], -0.008, t))\n",
    "\n",
    "# Make new mpg series -- annual growth rate: 0.7%\n",
    "mpg = [v for v in df[\"mpg\"]]\n",
    "for t in year_extension_range:\n",
    "    mpg.append(get_future_value(mpg[last_available_year_index], 0.007, t))\n",
    "\n",
    "# Make new vehicles/drivers series -- annual growth rate: 0.9%\n",
    "vehicles_per_driver_1 = [v for v in df[\"vehicles\"]/df[\"drivers\"]]\n",
    "for t in year_extension_range:\n",
    "    vehicles_per_driver_1.append(get_future_value(vehicles_per_driver_1[last_available_year_index], 0.009, t))\n",
    "\n",
    "# Make alternative vehicles/drivers series where the value remains at the 1994 value - annual growth rate: 0\n",
    "vehicles_per_driver_2 = [v for v in df[\"vehicles\"]/df[\"drivers\"]]\n",
    "for t in year_extension_range:\n",
    "    vehicles_per_driver_2.append(get_future_value(vehicles_per_driver_2[last_available_year_index], 0, t))\n",
    "\n",
    "# Make new psuburbs series -- annual growth rate: 1.7%\n",
    "# Remember, first need to pad 1991-1994 values of psuburbs which are otherwise unavailable\n",
    "psuburbs = [float(v) for v in df[\"psuburbs\"][:-4]]\n",
    "for i in range(4):\n",
    "    psuburbs.append(psuburbs[-1])\n",
    "for t in year_extension_range:\n",
    "    psuburbs.append(get_future_value(psuburbs[last_available_year_index], 0.017, t))\n",
    "\n",
    "# Dataset 1\n",
    "vmt_per_vehicle_2016_1_df = pd.DataFrame({\n",
    "    YEAR: years,\n",
    "    LOG_GDP_PER_CAPITA: np.log(gdp_per_capita),\n",
    "    LOG_PFUEL_PER_GALLON: np.log(pfuel_per_gallon),\n",
    "    LOG_MPG: np.log(mpg),\n",
    "    LOG_VEHICLES_PER_DRIVER: np.log(vehicles_per_driver_1),\n",
    "    LOG_PSUBURBS: np.log(psuburbs)\n",
    "})\n",
    "\n",
    "# Data set 2 -- the difference is vehicles/driver\n",
    "vmt_per_vehicle_2016_2_df = pd.DataFrame({\n",
    "    YEAR: years,\n",
    "    LOG_GDP_PER_CAPITA: np.log(gdp_per_capita),\n",
    "    LOG_PFUEL_PER_GALLON: np.log(pfuel_per_gallon),\n",
    "    LOG_MPG: np.log(mpg),\n",
    "    LOG_VEHICLES_PER_DRIVER: np.log(vehicles_per_driver_2),\n",
    "    LOG_PSUBURBS: np.log(psuburbs)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1 for VMT/Vehicles for 2016: 12308.602946157378\n",
      "Prediction 2 for ln VMT/Vehicles for 2016: 13961.376970592748\n"
     ]
    }
   ],
   "source": [
    "# Make prediction of VMT/Vehicles using dataset 1 prepared directly above\n",
    "# The model is used with estimates from part (d)\n",
    "vmt_per_vehicle_2016_1_X = sm.add_constant(vmt_per_vehicle_2016_1_df[[\n",
    "    LOG_GDP_PER_CAPITA,\n",
    "    LOG_PFUEL_PER_GALLON,\n",
    "    LOG_MPG,\n",
    "    LOG_VEHICLES_PER_DRIVER,\n",
    "    LOG_PSUBURBS,\n",
    "]]).iloc[-1]\n",
    "\n",
    "vmt_per_vehicle_2016_1_prediction = np.dot(vmt_per_vehicle_results_1.params, vmt_per_vehicle_2016_1_X)\n",
    "print(\"Prediction 1 for VMT/Vehicles for 2016:\", np.exp(vmt_per_vehicle_2016_1_prediction)*1000)\n",
    "\n",
    "# Make prediction of VMT/Vehicles using dataset 2 prepared directly above\n",
    "vmt_per_vehicle_2016_2_X = sm.add_constant(vmt_per_vehicle_2016_2_df[[\n",
    "    LOG_GDP_PER_CAPITA,\n",
    "    LOG_PFUEL_PER_GALLON,\n",
    "    LOG_MPG,\n",
    "    LOG_VEHICLES_PER_DRIVER,\n",
    "    LOG_PSUBURBS,\n",
    "]]).iloc[-1]\n",
    "vmt_per_vehicle_2016_2_prediction = np.dot(vmt_per_vehicle_results_1.params, vmt_per_vehicle_2016_2_X)\n",
    "# Transform value into true value: raise to e and convert units.\n",
    "# VMT is reported in millions of miles, and vehicles is reported in 1000's.  1,000,000/1000 = 1000\n",
    "print(\"Prediction 2 for ln VMT/Vehicles for 2016:\", np.exp(vmt_per_vehicle_2016_2_prediction)*1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VMT/drivers for dataset 1:\n",
      "16329.55884138165\n",
      "VMT/drivers for dataset 2:\n",
      "15208.566675171449\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In order to interpret what these numbers mean in relation to Kiefer and Mehndiratta’s hypothesis,\n",
    "I multiply these VMT/Vehicles rates by the forecasted Vehicles/drivers rates for 2016,\n",
    "in order to end up with estimates for VMT/drivers.\n",
    "\"\"\"\n",
    "\n",
    "print(\"VMT/drivers for dataset 1:\")\n",
    "print(np.exp(vmt_per_vehicle_2016_1_prediction)*vehicles_per_driver_1[-1])\n",
    "\n",
    "print(\"VMT/drivers for dataset 2:\")\n",
    "print(np.exp(vmt_per_vehicle_2016_2_prediction)*vehicles_per_driver_2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecasted price of fuel per gallon in 1987 US dollars:\n",
      "0.9050666096172386\n"
     ]
    }
   ],
   "source": [
    "# Does the forecasted 2016 price of fuel per gallon seem reasonable?\n",
    "print(\"forecasted price of fuel per gallon in 1987 US dollars:\")\n",
    "print(pfuel_per_gallon[-1])\n",
    "# The value is 0.91 which is equivalent to about ~$1.90 2016 US dollars.\n",
    "# This forecasted value is well below the true 2016 price of gas. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
